{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85790766",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %%capture prevents this cell from printing a ton of STDERR stuff to the screen\n",
    "\n",
    "## First, check to see if lightning is installed, if not, install it.\n",
    "##\n",
    "## NOTE: If you **do** need to install something, just know that you may need to\n",
    "##       restart your session for python to find the new module(s).\n",
    "##\n",
    "##       To restart your session:\n",
    "##       - In Google Colab, click on the \"Runtime\" menu and select\n",
    "##         \"Restart Session\" from the pulldown menu\n",
    "##       - In a local jupyter notebook, click on the \"Kernel\" menu and select\n",
    "##         \"Restart Kernel\" from the pulldown menu\n",
    "import pip\n",
    "try:\n",
    "  __import__(\"lightning\")\n",
    "except ImportError:\n",
    "  pip.main(['install', \"lightning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab47b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import lightning as L\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d64cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, we create a dictionary that maps vocabulary tokens to id numbers...\n",
    "english_token_to_id = {\n",
    "    \"lets\": 0,\n",
    "    \"to\": 1,\n",
    "    \"go\": 2,\n",
    "    \"<EOS>\": 3,  ## <EOS> = end of sequence\n",
    "}\n",
    "## ...then we create a dictionary that maps the ids to tokens. This will help us interpret the output.\n",
    "## We use the \"map()\" function to apply the \"reversed()\" function to each tuple (i.e. ('lets', 0)) stored\n",
    "## in the token_to_id dictionary. We then use dict() to make a new dictionary from the\n",
    "## reversed tuples.\n",
    "english_id_to_token = dict(map(reversed, english_token_to_id.items()))\n",
    "\n",
    "spanish_token_to_id = {\"ir\": 0, \"vamos\": 1, \"y\": 2, \"<EOS>\": 3}\n",
    "spanish_id_to_token = dict(map(reversed, spanish_token_to_id.items()))\n",
    "\n",
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [english_token_to_id[\"lets\"], english_token_to_id[\"go\"]],\n",
    "        [english_token_to_id[\"to\"], english_token_to_id[\"go\"]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "labels = torch.tensor(\n",
    "    [\n",
    "        [spanish_token_to_id[\"vamos\"], spanish_token_to_id[\"<EOS>\"]],\n",
    "        [spanish_token_to_id[\"ir\"], spanish_token_to_id[\"<EOS>\"]],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caae96b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [0, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea221a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "164ed1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(L.LightningModule):\n",
    "\n",
    "    def __init__(self, max_len=2):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_output_length = max_len\n",
    "\n",
    "        L.seed_everything(seed=420)\n",
    "\n",
    "        #################################\n",
    "        ##\n",
    "        ## ENCODING\n",
    "        ##\n",
    "        #################################\n",
    "        self.encoder_we = nn.Embedding(\n",
    "            num_embeddings=4,  # num_embeddings = # of words in input vocabulary\n",
    "            embedding_dim=2,\n",
    "        )  # embedding_dim = 2 numbers per embedding\n",
    "\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_size=2,  # input_size = number of inputs (2 numbers per word)\n",
    "            hidden_size=2,  # hidden_size = number of outputs (2 per word per layer)\n",
    "            num_layers=2,\n",
    "        )  # num_layers = how many lstm's to stack\n",
    "        #          If there are 2 layers, then the short term memory from the\n",
    "        #          first layer is used as input to the second layer\n",
    "\n",
    "        #################################\n",
    "        ##\n",
    "        ## DECODING\n",
    "        ##\n",
    "        #################################\n",
    "        self.decoder_we = nn.Embedding(num_embeddings=4, embedding_dim=2)\n",
    "\n",
    "        self.decoder_lstm = nn.LSTM(input_size=2, hidden_size=2, num_layers=2)\n",
    "\n",
    "        self.output_fc = nn.Linear(\n",
    "            in_features=2, out_features=4  # in_features = # of outputs per LSTM\n",
    "        )  # out_features = # of words in the output vocabulary\n",
    "\n",
    "        #################################\n",
    "        ##\n",
    "        ## Training\n",
    "        ##\n",
    "        #################################\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input, output=None):\n",
    "\n",
    "        #################################\n",
    "        ##\n",
    "        ## ENCODING\n",
    "        ##\n",
    "        #################################\n",
    "        ## first, use the encoder stage to create an intermediate encoding of the input text\n",
    "        encoder_embeddings = self.encoder_we(input)\n",
    "        encoder_lstm_output, (encoder_lstm_hidden, encoder_lstm_cell) = (\n",
    "            self.encoder_lstm(encoder_embeddings)\n",
    "        )\n",
    "\n",
    "        #################################\n",
    "        ##\n",
    "        ## DECODING\n",
    "        ##\n",
    "        #################################\n",
    "        ## We start by initializing the decoder with the <EOS> token...\n",
    "        decoder_token_id = torch.tensor([spanish_token_to_id[\"<EOS>\"]])\n",
    "        decoder_embeddings = self.decoder_we(decoder_token_id)\n",
    "\n",
    "        decoder_lstm_output, (decoder_lstm_hidden, decoder_lstm_cell) = (\n",
    "            self.decoder_lstm(\n",
    "                decoder_embeddings, (encoder_lstm_hidden, encoder_lstm_cell)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        output_values = self.output_fc(decoder_lstm_output)\n",
    "        outputs = output_values\n",
    "\n",
    "        predicted_id = torch.tensor([torch.argmax(output_values)])\n",
    "        predicted_ids = predicted_id\n",
    "\n",
    "        for i in range(1, self.max_output_length):\n",
    "\n",
    "            if output == None:  # using the model...\n",
    "                if (\n",
    "                    predicted_id == spanish_token_to_id[\"<EOS>\"]\n",
    "                ):  # if the prediction is <EOS>, then we are done\n",
    "                    break\n",
    "                decoder_embeddings = self.decoder_we(predicted_id)\n",
    "            else:\n",
    "                ## run this when training the model\n",
    "                decoder_embeddings = self.decoder_we(torch.tensor([output[i - 1]]))\n",
    "\n",
    "            decoder_lstm_output, (decoder_lstm_hidden, decoder_lstm_cell) = (\n",
    "                self.decoder_lstm(\n",
    "                    decoder_embeddings, (decoder_lstm_hidden, decoder_lstm_cell)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            output_values = self.output_fc(decoder_lstm_output)\n",
    "            outputs = torch.cat((outputs, output_values), 0)\n",
    "            predicted_id = torch.tensor([torch.argmax(output_values)])\n",
    "            predicted_ids = torch.cat((predicted_ids, predicted_id))\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ):  # this configures the optimizer we want to use for backpropagation.\n",
    "        return Adam(\n",
    "            self.parameters(), lr=0.1\n",
    "        )  ## NOTE: Setting the learning rate to 0.1 trains way faster than\n",
    "        ## using the default learning rate, lr=0.001\n",
    "\n",
    "    def training_step(self, batch, batch_idx):  # take a step during gradient descent.\n",
    "        input_tokens, labels = batch  # collect input\n",
    "        output = self.forward(\n",
    "            input_tokens[0], labels[0]\n",
    "        )  # run input through the neural network\n",
    "        loss = self.loss(output, labels[0])  ## self.loss = cross entropy\n",
    "        ###################\n",
    "        ##\n",
    "        ## Logging the loss\n",
    "        ##\n",
    "        ###################\n",
    "        # self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a9e7631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:\n",
      "\t y\n",
      "\t y\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq()\n",
    "outputs = model.forward(\n",
    "    input=torch.tensor(\n",
    "        [english_token_to_id[\"lets\"], english_token_to_id[\"go\"]]\n",
    "    ),  ## translate \"lets go\", we should get \"vamos <EOS>\"\n",
    "    output=None,\n",
    ")\n",
    "\n",
    "print(\"Translated text:\")\n",
    "predicted_ids = torch.argmax(outputs, dim=1)\n",
    "for id in predicted_ids:\n",
    "    print(\"\\t\", spanish_id_to_token[id.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3df66943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/hadi/Documents/statquest/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name         | Type             | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encode_we    | Embedding        | 8      | train\n",
      "1 | encoder_lstm | LSTM             | 96     | train\n",
      "2 | decoder_we   | Embedding        | 8      | train\n",
      "3 | decoder_lstm | LSTM             | 96     | train\n",
      "4 | output_fc    | Linear           | 12     | train\n",
      "5 | loss         | CrossEntropyLoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "220       Trainable params\n",
      "0         Non-trainable params\n",
      "220       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/hadi/Documents/statquest/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/hadi/Documents/statquest/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dbe57bfc874f529ae4751237d54841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=40, accelerator=\"cpu\")\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3affd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:\n",
      "\t ir\n",
      "\t <EOS>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.forward(\n",
    "    input=torch.tensor(\n",
    "        [english_token_to_id[\"lets\"], english_token_to_id[\"go\"]]\n",
    "    ),  ## translate \"lets go\", we should get \"vamos <EOS>\"\n",
    "    output=None,\n",
    ")\n",
    "\n",
    "print(\"Translated text:\")\n",
    "predicted_ids = torch.argmax(outputs, dim=1)\n",
    "for id in predicted_ids:\n",
    "    print(\"\\t\", spanish_id_to_token[id.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22fd44e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:\n",
      "\t ir\n",
      "\t <EOS>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.forward(\n",
    "    input=torch.tensor(\n",
    "        [english_token_to_id[\"to\"], english_token_to_id[\"go\"]]\n",
    "    ),  ## translate \"lets go\", we should get \"vamos <EOS>\"\n",
    "    output=None,\n",
    ")\n",
    "\n",
    "print(\"Translated text:\")\n",
    "predicted_ids = torch.argmax(outputs, dim=1)\n",
    "for id in predicted_ids:\n",
    "    print(\"\\t\", spanish_id_to_token[id.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0647957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 220\n"
     ]
    }
   ],
   "source": [
    "## count the number of parameters...\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Total number of trainable parameters:\", total_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9f48db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\n",
    "    \"seq2seq_en2es_220_trained.ckpt\"\n",
    ")  ## NOTE: You can specify a path as part of the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f618f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text:\n",
      "\t ir\n",
      "\t <EOS>\n"
     ]
    }
   ],
   "source": [
    "new_model = Seq2Seq.load_from_checkpoint(\"seq2seq_en2es_220_trained.ckpt\")\n",
    "\n",
    "outputs = new_model.forward(\n",
    "    input=torch.tensor([english_token_to_id[\"lets\"], english_token_to_id[\"go\"]]),\n",
    "    output=None,\n",
    ")\n",
    "\n",
    "print(\"Translated text:\")\n",
    "predicted_ids = torch.argmax(outputs, dim=1)\n",
    "for id in predicted_ids:\n",
    "    print(\"\\t\", spanish_id_to_token[id.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76dccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
